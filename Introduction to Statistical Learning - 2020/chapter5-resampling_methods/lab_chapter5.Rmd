---
title: >
  ISL - Chapter 5 Labs
author: XXX
output: 
  html_document:
  # BiocStyle::html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: cosmo
    code_folding: show
    code_download: true
editor_options: 
  chunk_output_type: console

---

Cross-Validation and the Bootstrap

# The Validation Set Approach

```{r}
library("ISLR")

# to be consistent with R < 3.6.0: 
## RNGkind(sample.kind = "Rounding")

# training set 1
set.seed(1)
train <- sample(392, 196, replace = FALSE)
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)

# attach(Auto)
Auto
dim(Auto)
plot(Auto$horsepower, Auto$mpg)
mean((Auto$mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)
mean((Auto$mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)
mean((Auto$mpg - predict(lm.fit3, Auto))[-train]^2)

# training set 2
set.seed(2)
train <- sample(392, 196, replace = FALSE)
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
mean((Auto$mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)
mean((Auto$mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)
mean((Auto$mpg - predict(lm.fit3, Auto))[-train]^2)
```

# Leave-One-Out Cross-Validation

```{r}
glm.fit <- glm(mpg ~ horsepower, data = Auto)
coef(glm.fit)
lm.fit <- lm(mpg ~ horsepower, data = Auto)
coef(lm.fit)

library("boot")
glm.fit <- glm(mpg ~ horsepower, data = Auto)
cv.err <- cv.glm(Auto, glm.fit) # default k: number of observations = LOOCV
cv.err$delta # cross-validation estimate of prediction error

cv.error <- rep(0, 5)
for (i in 1:5) {
  glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
  cv.error[i] <- cv.glm(Auto, glm.fit)$delta[1] # function does not make use of formula 5.2
}
cv.error
```

# k-Fold Cross-Validation

```{r}
set.seed(17)
cv.error.10 <- rep(0, 10)
for (i in 1:10) {
  glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
  cv.error.10[i] <- cv.glm(Auto, glm.fit, K = 10)$delta[1]
}
cv.error.10
plot(cv.error.10)

```

# The Bootstrap

```{r}
head(Portfolio)
colnames(Portfolio)
summary(Portfolio)
dim(Portfolio)

alpha.fn <- function(data, index) {
  X <- data$X[index]
  Y <- data$Y[index]
  return((var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y)))
}
alpha.fn(Portfolio, 1:100)

set.seed(1)

s <- sample(100, 100, replace = TRUE)
table(s)
table(table(s))
alpha.fn(Portfolio, s)

boot(Portfolio, alpha.fn, R = 1000)


set.seed(1)
b <- boot(Portfolio, alpha.fn, R = 1000) # repeat 1000 times
b
b$t0 # original
head(b$t)
mean(b$t-b$t0) # bias
sd(b$t) # standard error
plot(b)
```

# Estimating the Accuracy of a Linear Regression Model

```{r}
boot.fn <- function(data, index) {
  return(coef(lm(mpg ~ horsepower, data = data, subset = index)))
}

boot.fn(Auto, 1:392)
set.seed(1)
boot.fn(Auto, sample(392, 392, replace = T))
boot.fn(Auto, sample(392, 392, replace = T))
boot(Auto, boot.fn, 1000)
summary(lm(mpg ~ horsepower, data = Auto))$coef
boot.fn <- function(data, index) {
  coefficients(lm(mpg ~ horsepower + I(horsepower^2), data = data, subset = index))
}
set.seed(1)
boot(Auto, boot.fn, 1000)
summary(lm(mpg ~ horsepower + I(horsepower^2), data = Auto))$coef
```

# Session Info {-} 

```{r}
sessionInfo()
```

